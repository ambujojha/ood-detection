{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_px(ppl, lls):\n",
    "    lengths = np.array([len(ll) for ll in lls])\n",
    "    logpx = np.log(ppl) * lengths * -1\n",
    "    return logpx\n",
    "\n",
    "def compute_auroc_all(id_msp, id_px, id_ppl, ood_msp, ood_px, ood_ppl, do_print=False):\n",
    "    score_px = compute_auroc(-id_px, -ood_px)\n",
    "    score_py = compute_auroc(-id_msp, -ood_msp)\n",
    "    score_ppl = compute_auroc(id_ppl, ood_ppl)\n",
    "    if do_print:\n",
    "        print(f\"P(x): {score_px:.3f}\")\n",
    "        print(f\"P(y | x): {score_py:.3f}\")\n",
    "        print(f\"Perplexity: {score_ppl:.3f}\")\n",
    "    scores = {\n",
    "        'p_x': score_px,\n",
    "        'p_y': score_py,\n",
    "        'ppl': score_ppl\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_auroc(id_pps, ood_pps, normalize=False, return_curve=False):\n",
    "    y = np.concatenate((np.ones_like(ood_pps), np.zeros_like(id_pps)))\n",
    "    scores = np.concatenate((ood_pps, id_pps))\n",
    "    if normalize:\n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    if return_curve:\n",
    "        return roc_curve(y, scores)\n",
    "    else:\n",
    "        return 100*roc_auc_score(y, scores)\n",
    "\n",
    "def compute_far(id_pps, ood_pps, rate=5, return_indices=False):\n",
    "    if return_indices:\n",
    "        cut_off = np.percentile(ood_pps, rate)\n",
    "        id_indices = [i for i, pps in enumerate(id_pps) if pps > cut_off]\n",
    "        ood_indices = [i for i, pps in enumerate(ood_pps) if pps < cut_off]\n",
    "        return {'id': id_indices, 'ood': ood_indices}\n",
    "    else:\n",
    "        incorrect = len(id_pps[id_pps > np.percentile(ood_pps, rate)])\n",
    "        return 100*incorrect / len(id_pps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_all(id_msp, id_px, id_ppl, ood_msp, ood_px, ood_ppl, metric='auroc', do_print=False):\n",
    "    if metric == 'auroc':\n",
    "        score_px = compute_auroc(-id_px, -ood_px)\n",
    "        score_py = compute_auroc(-id_msp, -ood_msp)\n",
    "        score_ppl = compute_auroc(id_ppl, ood_ppl)\n",
    "    elif metric == 'far':\n",
    "        score_px = compute_far(-id_px, -ood_px)\n",
    "        score_py = compute_far(-id_msp, -ood_msp)\n",
    "        score_ppl = compute_far(id_ppl, ood_ppl)\n",
    "    else:\n",
    "        raise Exception('Invalid metric name')\n",
    "\n",
    "    if do_print:\n",
    "        print(f\"Metric {metric}:\")\n",
    "        print(f\"P(x): {score_px:.3f}\")\n",
    "        print(f\"P(y | x): {score_py:.3f}\")\n",
    "        print(f\"Perplexity: {score_ppl:.3f}\\n\")\n",
    "\n",
    "    scores = {\n",
    "        'p_x': score_px,\n",
    "        'p_y': score_py,\n",
    "        'ppl': score_ppl\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_model_out(fname):\n",
    "    ftype = fname.split('.')[1]\n",
    "    \n",
    "    if ftype == 'pkl':\n",
    "        with open(fname, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    elif ftype == 'npy':\n",
    "        return np.load(fname)\n",
    "    else:\n",
    "        raise KeyError(f'{ftype} not supported')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Documents\\NYU\\2020_Fall\\nlp\\project\\ood-detection\n"
     ]
    }
   ],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(repo, 'output')\n",
    "fig_dir = os.path.join(repo, 'figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = ['imdb', 'sst2']\n",
    "eval_sets = ['imdb', 'sst2', 'snli', 'counterfactual-imdb', 'rte']\n",
    "methods = ['msp', 'lls', 'pps']\n",
    "\n",
    "signals = {}\n",
    "for train_set in train_sets:\n",
    "    for eval_set in eval_sets:\n",
    "        signals[(train_set, eval_set)] = {method: None for method in methods}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "method2ftype={\n",
    "    'msp': 'npy',\n",
    "    'lls': 'pkl',\n",
    "    'pps': 'npy',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        return [int(x) for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_dir = os.path.join(repo, 'roberta')\n",
    "\n",
    "subsample_indices = {\n",
    "    data_name: get_indices(os.path.join(roberta_dir, f'{data_name}_indices.txt'))\n",
    "    for data_name in train_sets\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = {\n",
    "    'imdb': '5e-5',\n",
    "    'sst2': '5e-5',\n",
    "}\n",
    "\n",
    "methods = ['lls', 'pps']\n",
    "not_readys = []\n",
    "\n",
    "for (train_set, eval_set), signals_dict in signals.items():\n",
    "    for method in methods:\n",
    "        signal_fname = os.path.join(output_dir, 'gpt2', train_set, f'{eval_set}_{best_lr[train_set]}_{method}.{method2ftype[method]}')\n",
    "        if not os.path.exists(signal_fname):\n",
    "            not_readys.append((train_set, eval_set, method))\n",
    "            continue\n",
    "        \n",
    "        signal = read_model_out(signal_fname)\n",
    "        if eval_set in train_sets:\n",
    "            idxs = subsample_indices[eval_set]\n",
    "            signal = [signal[idx] for idx in idxs]\n",
    "        \n",
    "        signals_dict[method] = signal\n",
    "        \n",
    "for not_ready in not_readys:\n",
    "    print(not_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['msp']\n",
    "not_readys = []\n",
    "\n",
    "model_type = 'roberta-base'\n",
    "\n",
    "for (train_set, eval_set), signals_dict in signals.items():\n",
    "    for method in methods:\n",
    "        signal_fname = os.path.join(output_dir, 'roberta', train_set, f'{model_type}_{eval_set}_{method}.{method2ftype[method]}')\n",
    "        if not os.path.exists(signal_fname):\n",
    "            not_readys.append((train_set, eval_set, method))\n",
    "            continue\n",
    "            \n",
    "        signal = read_model_out(signal_fname)\n",
    "        if train_set != eval_set and eval_set in train_sets:\n",
    "            idxs = subsample_indices[eval_set]\n",
    "            signal = np.array([signal[idx] for idx in idxs])\n",
    "        \n",
    "        signals_dict[method] = signal\n",
    "        \n",
    "for not_ready in not_readys:\n",
    "    print(not_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Error Indices by FAR95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score2plot = {\n",
    "    'p_x': r'GPT2: $p(x)$',\n",
    "    'ppl': 'GPT2: PPL',\n",
    "    'p_y': 'RoBERTa: MSP',\n",
    "}\n",
    "\n",
    "metric2plot = {\n",
    "    'auroc': 'AUROC',\n",
    "    'far': 'FAR95'\n",
    "}\n",
    "\n",
    "dataset2plot = {\n",
    "    'imdb': 'IMDB',\n",
    "    'sst2': 'SST-2',\n",
    "    'snli': 'SNLI',\n",
    "    'counterfactual-imdb': 'c-IMDB',\n",
    "    'rte': 'RTE',\n",
    "}\n",
    "\n",
    "error_indices = {}\n",
    "not_ready = []\n",
    "for train_set in train_sets:\n",
    "    for eval_set in eval_sets:\n",
    "        if train_set == eval_set:\n",
    "            continue\n",
    "        \n",
    "        ood_signal_dict = signals[(train_set, eval_set)]\n",
    "        id_signal_dict = signals[(train_set, train_set)]\n",
    "        \n",
    "        skip=False\n",
    "        for value in ood_signal_dict.values():\n",
    "            if isinstance(value, type(None)):\n",
    "                skip=True\n",
    "                \n",
    "        if skip:\n",
    "            not_ready.append((train_set, eval_set))\n",
    "            continue\n",
    "        \n",
    "        pps_errors = compute_far(id_signal_dict['pps'], ood_signal_dict['pps'], return_indices=True)\n",
    "        msp_errors = compute_far(-id_signal_dict['msp'], -ood_signal_dict['msp'], return_indices=True)\n",
    "        \n",
    "        error_indices[(train_set, eval_set)] = {'pps': pps_errors, 'msp': msp_errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('imdb', 'sst2'), ('imdb', 'snli'), ('imdb', 'counterfactual-imdb'), ('imdb', 'rte'), ('sst2', 'imdb'), ('sst2', 'snli'), ('sst2', 'counterfactual-imdb'), ('sst2', 'rte')]\n"
     ]
    }
   ],
   "source": [
    "print(list(error_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_parts = {}\n",
    "for ood_key, errors_dict in error_indices.items():\n",
    "    pps_id = set(errors_dict['pps']['id'])\n",
    "    pps_ood = set(errors_dict['pps']['ood'])\n",
    "    msp_id = set(errors_dict['msp']['id'])\n",
    "    msp_ood = set(errors_dict['msp']['ood'])\n",
    "    \n",
    "    union = {\n",
    "        'id': pps_id.union(msp_id),\n",
    "        'ood': pps_ood.union(msp_ood),\n",
    "    }\n",
    "    \n",
    "    common = {\n",
    "        'id': pps_id.intersection(msp_id),\n",
    "        'ood': pps_ood.intersection(msp_ood),\n",
    "    }\n",
    "    \n",
    "    pps_only = {\n",
    "        'id': pps_id.difference(msp_id),\n",
    "        'ood': pps_ood.difference(msp_ood),\n",
    "    }\n",
    "    \n",
    "    msp_only = {\n",
    "        'id': msp_id.difference(pps_id),\n",
    "        'ood': msp_ood.difference(pps_ood),\n",
    "    }\n",
    "    \n",
    "    indices_parts[ood_key] = {\n",
    "        'union': union,\n",
    "        'common': common,\n",
    "        'pps': pps_only,\n",
    "        'msp': msp_only,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  in domain                  ood  total count  common count  msp only count  \\\n",
      "0      imdb                 sst2        18063          6200           10932   \n",
      "1      imdb                 snli        19371          2874             637   \n",
      "2      imdb  counterfactual-imdb        19920         16083            1408   \n",
      "3      imdb                  rte        19770          4077              48   \n",
      "4      sst2                 imdb         2429           177            1362   \n",
      "5      sst2                 snli         1261            97             600   \n",
      "6      sst2  counterfactual-imdb          723            50             551   \n",
      "7      sst2                  rte          363            85             173   \n",
      "\n",
      "   pps only count  common ratio  msp only ratio  pps only ratio  \n",
      "0             931      0.343243        0.605215        0.051542  \n",
      "1           15860      0.148366        0.032884        0.818750  \n",
      "2            2429      0.807380        0.070683        0.121938  \n",
      "3           15645      0.206222        0.002428        0.791351  \n",
      "4             890      0.072869        0.560725        0.366406  \n",
      "5             564      0.076923        0.475813        0.447264  \n",
      "6             122      0.069156        0.762102        0.168741  \n",
      "7             105      0.234160        0.476584        0.289256  \n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "for (indomain, ood), partitions in indices_parts.items():\n",
    "    total_count = len(partitions['union']['id']) + len(partitions['union']['ood'])\n",
    "    common_count = len(partitions['common']['id']) + len(partitions['common']['ood'])\n",
    "    msp_count = len(partitions['msp']['id']) + len(partitions['msp']['ood']) + common_count\n",
    "    pps_count = len(partitions['pps']['id']) + len(partitions['pps']['ood']) + common_count\n",
    "    \n",
    "    row = {\n",
    "        'in domain': indomain,\n",
    "        'ood': ood,\n",
    "        'total count': total_count,\n",
    "        'common count': common_count,\n",
    "        'msp only count': msp_count - common_count,\n",
    "        'pps only count': pps_count - common_count,\n",
    "        'common ratio': common_count/total_count,\n",
    "        'msp only ratio': (msp_count - common_count)/total_count,\n",
    "        'pps only ratio': (pps_count - common_count)/total_count,\n",
    "    }\n",
    "    \n",
    "    stats.append(row)\n",
    "print(pd.DataFrame(stats))\n",
    "pd.DataFrame(stats).to_csv(os.path.join('.', 'error_analysis', 'error_counts_ratios.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('.', 'all_val_data.p'), 'rb') as f:\n",
    "    datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb sst2 common id\n",
      "imdb sst2 common ood\n",
      "imdb sst2 msp id\n",
      "imdb sst2 msp ood\n",
      "imdb sst2 pps id\n",
      "imdb sst2 pps ood\n",
      "imdb snli common id\n",
      "imdb snli common ood\n",
      "imdb snli msp id\n",
      "imdb snli msp ood\n",
      "imdb snli pps id\n",
      "imdb snli pps ood\n",
      "imdb counterfactual-imdb common id\n",
      "imdb counterfactual-imdb common ood\n",
      "imdb counterfactual-imdb msp id\n",
      "imdb counterfactual-imdb msp ood\n",
      "imdb counterfactual-imdb pps id\n",
      "imdb counterfactual-imdb pps ood\n",
      "imdb rte common id\n",
      "imdb rte common ood\n",
      "imdb rte msp id\n",
      "imdb rte msp ood\n",
      "imdb rte pps id\n",
      "imdb rte pps ood\n",
      "sst2 imdb common id\n",
      "sst2 imdb common ood\n",
      "sst2 imdb msp id\n",
      "sst2 imdb msp ood\n",
      "sst2 imdb pps id\n",
      "sst2 imdb pps ood\n",
      "sst2 snli common id\n",
      "sst2 snli common ood\n",
      "sst2 snli msp id\n",
      "sst2 snli msp ood\n",
      "sst2 snli pps id\n",
      "sst2 snli pps ood\n",
      "sst2 counterfactual-imdb common id\n",
      "sst2 counterfactual-imdb common ood\n",
      "sst2 counterfactual-imdb msp id\n",
      "sst2 counterfactual-imdb msp ood\n",
      "sst2 counterfactual-imdb pps id\n",
      "sst2 counterfactual-imdb pps ood\n",
      "sst2 rte common id\n",
      "sst2 rte common ood\n",
      "sst2 rte msp id\n",
      "sst2 rte msp ood\n",
      "sst2 rte pps id\n",
      "sst2 rte pps ood\n"
     ]
    }
   ],
   "source": [
    "nsample = 10\n",
    "examples = []\n",
    "ignore_ood = []\n",
    "parts = ['common', 'msp', 'pps']\n",
    "domains = ['id', 'ood']\n",
    "\n",
    "for (indomain, ood), partitions in indices_parts.items():\n",
    "    if ood in ignore_ood:\n",
    "        continue\n",
    "        \n",
    "    data = {\n",
    "        'id': datasets[('id', 'val', indomain)]['text'],\n",
    "        'ood': datasets[('ood', 'val', ood)]['text'],\n",
    "    }\n",
    "    \n",
    "    for part in parts:\n",
    "        for domain in domains:\n",
    "            sample_size = min(nsample, len(partitions[part][domain]))\n",
    "            sample = np.random.choice(list(partitions[part][domain]), size=sample_size, replace=False)\n",
    "            print(indomain, ood, part, domain)\n",
    "            for idx in sample:\n",
    "                examples.append({\n",
    "                    'in domain': indomain,\n",
    "                    'ood': ood,\n",
    "                    'text': data[domain][idx],\n",
    "                    'domain': domain,\n",
    "                    'dataset': indomain if domain == 'id' else ood,\n",
    "                    'partition': part,\n",
    "                })\n",
    "pd.DataFrame(examples).to_csv(os.path.join('.', 'error_analysis', 'error_examples.csv'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent OOD Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "        return re.sub(regex, ' ', text)\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "    #return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "    return white_space_fix(remove_punc(lower(s)))\n",
    "\n",
    "\n",
    "def get_tokens(s):\n",
    "    if not s: return []\n",
    "    return normalize_text(s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb sst2 common ood\n",
      "imdb sst2 msp ood\n",
      "imdb sst2 pps ood\n",
      "imdb snli common ood\n",
      "imdb snli msp ood\n",
      "imdb snli pps ood\n",
      "imdb counterfactual-imdb common ood\n",
      "imdb counterfactual-imdb msp ood\n",
      "imdb counterfactual-imdb pps ood\n",
      "imdb rte common ood\n",
      "imdb rte msp ood\n",
      "imdb rte pps ood\n",
      "sst2 imdb common ood\n",
      "sst2 imdb msp ood\n",
      "sst2 imdb pps ood\n",
      "sst2 snli common ood\n",
      "sst2 snli msp ood\n",
      "sst2 snli pps ood\n",
      "sst2 counterfactual-imdb common ood\n",
      "sst2 counterfactual-imdb msp ood\n",
      "sst2 counterfactual-imdb pps ood\n",
      "sst2 rte common ood\n",
      "sst2 rte msp ood\n",
      "sst2 rte pps ood\n"
     ]
    }
   ],
   "source": [
    "ood_stats, ood_examples = [], []\n",
    "\n",
    "ignore_tasks = []\n",
    "parts = ['common', 'msp', 'pps']\n",
    "domains = ['ood']\n",
    "\n",
    "nsample = 10\n",
    "\n",
    "for (indomain, ood), partitions in indices_parts.items():\n",
    "    if ood in ignore_tasks:\n",
    "        continue\n",
    "    \n",
    "    total_count = len(partitions['union']['ood'])\n",
    "    common_count = len(partitions['common']['ood'])\n",
    "    msp_count = len(partitions['msp']['ood']) + common_count\n",
    "    pps_count = len(partitions['pps']['ood']) + common_count\n",
    "    \n",
    "    row = {\n",
    "        'in domain': indomain,\n",
    "        'ood': ood,\n",
    "        'total count': total_count,\n",
    "        'common count': common_count,\n",
    "        'msp only count': msp_count - common_count,\n",
    "        'pps only count': pps_count - common_count,\n",
    "        'common ratio': common_count/total_count,\n",
    "        'msp only ratio': (msp_count - common_count)/total_count,\n",
    "        'pps only ratio': (pps_count - common_count)/total_count,\n",
    "    }\n",
    "    \n",
    "    ood_stats.append(row)\n",
    "    \n",
    "    \n",
    "    data = {'ood': datasets[('ood', 'val', ood)]}\n",
    "    for part in parts:\n",
    "        for domain in domains:\n",
    "            sample_size = min(nsample, len(partitions[part][domain]))\n",
    "            sample = np.random.choice(list(partitions[part][domain]), size=sample_size, replace=False)\n",
    "            print(indomain, ood, part, domain)\n",
    "            for idx in sample:\n",
    "                ood_examples.append({\n",
    "                    'in domain': indomain,\n",
    "                    'ood': ood,\n",
    "                    'text': data[domain]['text'][idx],\n",
    "                    'unigram length': len(get_tokens(data[domain]['text'][idx])),\n",
    "                    'label': data[domain]['label'][idx],                    \n",
    "                    'domain': domain,\n",
    "                    'dataset': indomain if domain == 'id' else ood,\n",
    "                    'partition': part,\n",
    "                })\n",
    "    \n",
    "    \n",
    "pd.DataFrame(ood_stats).to_csv(os.path.join('.', 'error_analysis', 'ood_error_counts_ratios.csv'))\n",
    "pd.DataFrame(ood_examples).to_csv(os.path.join('.', 'error_analysis', 'ood_error_examples.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ood_examples = []\n",
    "\n",
    "ignore_tasks = []\n",
    "parts = ['common', 'msp', 'pps']\n",
    "domains = ['ood']\n",
    "nli = ['snli', 'rte']\n",
    "\n",
    "nsample = 10\n",
    "\n",
    "for (indomain, ood), partitions in indices_parts.items():  \n",
    "    \n",
    "    data = {'ood': datasets[('ood', 'val', ood)]}\n",
    "    for part in parts:\n",
    "        for domain in domains:\n",
    "            for idx in list(partitions[part][domain]):\n",
    "                overlap = 0\n",
    "                if ood in nli:\n",
    "                    for punct in [ '.', '!', '?']:\n",
    "                        text_list = data[domain]['text'][idx].split(punct)\n",
    "                        if len(text_list) > 1:\n",
    "                            break\n",
    "                    if text_list[-1] == '':\n",
    "                        prem, hyp = ' '.join(text_list[:-2]), text_list[-2]\n",
    "                    else:\n",
    "                        prem, hyp = ' '.join(text_list[:-1]), text_list[-1]\n",
    "                    prem = set(prem.split(' '))\n",
    "                    hyp = set(hyp.split(' '))\n",
    "                    overlap = len(hyp.intersection(prem)) / len(hyp)\n",
    "                \n",
    "                all_ood_examples.append({\n",
    "                    'in domain': indomain,\n",
    "                    'ood': ood,\n",
    "                    'text': data[domain]['text'][idx],\n",
    "                    'unigram length': len(get_tokens(data[domain]['text'][idx])),\n",
    "                    'label': data[domain]['label'][idx],                    \n",
    "                    'domain': domain,\n",
    "                    'dataset': indomain if domain == 'id' else ood,\n",
    "                    'partition': part,\n",
    "                    'overlap': overlap\n",
    "                })            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ood_examples_df = pd.DataFrame(all_ood_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keeps = ['in domain', 'ood', 'unigram length', 'partition']\n",
    "groupby = ['in domain', 'ood', 'partition']\n",
    "\n",
    "grouped_lengths = all_ood_examples_df[keeps].groupby(groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               mean         std\n",
      "in domain ood                 partition                        \n",
      "imdb      counterfactual-imdb common     119.416667   52.344069\n",
      "                              msp        138.781818   69.840497\n",
      "                              pps        133.500000   59.319188\n",
      "          rte                 msp         66.214286   41.020030\n",
      "                              pps         51.214286   31.645096\n",
      "          snli                common      21.181818    7.807921\n",
      "                              msp         21.363450    8.628915\n",
      "                              pps         26.486708    8.826674\n",
      "          sst2                common      24.000000    4.000000\n",
      "                              msp         18.062500    7.922762\n",
      "                              pps         16.875000    8.914468\n",
      "sst2      counterfactual-imdb common     110.181818   41.787123\n",
      "                              msp        129.414414   59.180996\n",
      "                              pps        148.747748   60.585397\n",
      "          imdb                common     227.058824  162.157764\n",
      "                              msp        224.170455  178.608617\n",
      "                              pps        219.224745  152.214522\n",
      "          rte                 common      42.000000         NaN\n",
      "                              msp         51.769231   19.092555\n",
      "                              pps         36.769231   23.763255\n",
      "          snli                common      27.937500    8.031942\n",
      "                              msp         19.029915    6.476705\n",
      "                              pps         28.448718    8.928909\n"
     ]
    }
   ],
   "source": [
    "lengths_summary = grouped_lengths.mean()\n",
    "lengths_summary['std'] = grouped_lengths.std()['unigram length']\n",
    "lengths_summary = lengths_summary.rename(columns = {'unigram length':'mean'})\n",
    "print(lengths_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lengths_summary.to_csv(os.path.join('.', 'error_analysis', 'ood_error_lengths_stats.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "keeps = ['in domain', 'ood', 'label', 'partition', 'unigram length']\n",
    "groupby = ['in domain', 'ood', 'partition', 'label']\n",
    "\n",
    "grouped_labels = all_ood_examples_df[keeps].groupby(groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         total\n",
      "in domain ood                 partition       \n",
      "imdb      counterfactual-imdb common        12\n",
      "                              msp          110\n",
      "                              pps          110\n",
      "          rte                 msp           14\n",
      "                              pps           14\n",
      "          snli                common        11\n",
      "                              msp          487\n",
      "                              pps          489\n",
      "          sst2                common         3\n",
      "                              msp           32\n",
      "                              pps           32\n",
      "sst2      counterfactual-imdb common        11\n",
      "                              msp          111\n",
      "                              pps          111\n",
      "          imdb                common       119\n",
      "                              msp          880\n",
      "                              pps          881\n",
      "          rte                 common         1\n",
      "                              msp           13\n",
      "                              pps           13\n",
      "          snli                common        32\n",
      "                              msp          468\n",
      "                              pps          468\n"
     ]
    }
   ],
   "source": [
    "keeps = ['in domain', 'ood', 'partition', 'unigram length']\n",
    "groupby = ['in domain', 'ood', 'partition']\n",
    "\n",
    "grouped_counts = all_ood_examples_df[keeps].groupby(groupby)\n",
    "grouped_counts_df = grouped_counts.count().rename(columns = {'unigram length': 'total'})\n",
    "print(grouped_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  counts\n",
      "in domain ood                 partition label           \n",
      "imdb      counterfactual-imdb common    Negative      11\n",
      "                                        Positive       1\n",
      "                              msp       Negative      73\n",
      "                                        Positive      37\n",
      "                              pps       Negative      54\n",
      "                                        Positive      56\n",
      "          rte                 msp       0              9\n",
      "                                        1              5\n",
      "                              pps       0              9\n",
      "                                        1              5\n",
      "          snli                common    0              3\n",
      "                                        1              6\n",
      "                                        2              2\n",
      "                              msp       -1             9\n",
      "                                        0            175\n",
      "                                        1            147\n",
      "                                        2            156\n",
      "                              pps       -1             6\n",
      "                                        0            209\n",
      "                                        1            149\n",
      "                                        2            125\n",
      "          sst2                common    0              2\n",
      "                                        1              1\n",
      "                              msp       0             17\n",
      "                                        1             15\n",
      "                              pps       0             18\n",
      "                                        1             14\n",
      "sst2      counterfactual-imdb common    Negative       3\n",
      "                                        Positive       8\n",
      "                              msp       Negative      10\n",
      "                                        Positive     101\n",
      "                              pps       Negative      59\n",
      "                                        Positive      52\n",
      "          imdb                common    0             49\n",
      "                                        1             70\n",
      "                              msp       0            340\n",
      "                                        1            540\n",
      "                              pps       0            333\n",
      "                                        1            548\n",
      "          rte                 common    0              1\n",
      "                              msp       0              5\n",
      "                                        1              8\n",
      "                              pps       0              8\n",
      "                                        1              5\n",
      "          snli                common    0             12\n",
      "                                        1             10\n",
      "                                        2             10\n",
      "                              msp       -1             3\n",
      "                                        0            146\n",
      "                                        1            176\n",
      "                                        2            143\n",
      "                              pps       -1             6\n",
      "                                        0            184\n",
      "                                        1            145\n",
      "                                        2            133\n"
     ]
    }
   ],
   "source": [
    "labels_summary = grouped_labels.count().rename(columns = {'unigram length': 'counts'})\n",
    "print(labels_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  counts  total     ratio\n",
      "in domain ood                 partition label                            \n",
      "imdb      counterfactual-imdb common    Negative      11     12  0.916667\n",
      "                                        Positive       1     12  0.083333\n",
      "                              msp       Negative      73    110  0.663636\n",
      "                                        Positive      37    110  0.336364\n",
      "                              pps       Negative      54    110  0.490909\n",
      "                                        Positive      56    110  0.509091\n",
      "          rte                 msp       0              9     14  0.642857\n",
      "                                        1              5     14  0.357143\n",
      "                              pps       0              9     14  0.642857\n",
      "                                        1              5     14  0.357143\n",
      "          snli                common    0              3     11  0.272727\n",
      "                                        1              6     11  0.545455\n",
      "                                        2              2     11  0.181818\n",
      "                              msp       -1             9    487  0.018480\n",
      "                                        0            175    487  0.359343\n",
      "                                        1            147    487  0.301848\n",
      "                                        2            156    487  0.320329\n",
      "                              pps       -1             6    489  0.012270\n",
      "                                        0            209    489  0.427403\n",
      "                                        1            149    489  0.304703\n",
      "                                        2            125    489  0.255624\n",
      "          sst2                common    0              2      3  0.666667\n",
      "                                        1              1      3  0.333333\n",
      "                              msp       0             17     32  0.531250\n",
      "                                        1             15     32  0.468750\n",
      "                              pps       0             18     32  0.562500\n",
      "                                        1             14     32  0.437500\n",
      "sst2      counterfactual-imdb common    Negative       3     11  0.272727\n",
      "                                        Positive       8     11  0.727273\n",
      "                              msp       Negative      10    111  0.090090\n",
      "                                        Positive     101    111  0.909910\n",
      "                              pps       Negative      59    111  0.531532\n",
      "                                        Positive      52    111  0.468468\n",
      "          imdb                common    0             49    119  0.411765\n",
      "                                        1             70    119  0.588235\n",
      "                              msp       0            340    880  0.386364\n",
      "                                        1            540    880  0.613636\n",
      "                              pps       0            333    881  0.377980\n",
      "                                        1            548    881  0.622020\n",
      "          rte                 common    0              1      1  1.000000\n",
      "                              msp       0              5     13  0.384615\n",
      "                                        1              8     13  0.615385\n",
      "                              pps       0              8     13  0.615385\n",
      "                                        1              5     13  0.384615\n",
      "          snli                common    0             12     32  0.375000\n",
      "                                        1             10     32  0.312500\n",
      "                                        2             10     32  0.312500\n",
      "                              msp       -1             3    468  0.006410\n",
      "                                        0            146    468  0.311966\n",
      "                                        1            176    468  0.376068\n",
      "                                        2            143    468  0.305556\n",
      "                              pps       -1             6    468  0.012821\n",
      "                                        0            184    468  0.393162\n",
      "                                        1            145    468  0.309829\n",
      "                                        2            133    468  0.284188\n"
     ]
    }
   ],
   "source": [
    "labels_total_summary = labels_summary.join(grouped_counts_df, on=['in domain', 'ood', 'partition'], how='left')\n",
    "labels_total_summary['ratio'] = labels_total_summary['counts'] / labels_total_summary['total']\n",
    "print(labels_total_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels_total_summary.to_csv(os.path.join('.', 'error_analysis', 'ood_error_labels_stats.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = ['in domain', 'ood', 'overlap', 'partition']\n",
    "groupby = ['in domain', 'ood', 'partition']\n",
    "\n",
    "grouped_overlaps = all_ood_examples_df[keeps].groupby(groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             mean       std\n",
      "in domain ood                 partition                    \n",
      "imdb      counterfactual-imdb common     0.000000  0.000000\n",
      "                              msp        0.000000  0.000000\n",
      "                              pps        0.000000  0.000000\n",
      "          rte                 msp        0.528778  0.209247\n",
      "                              pps        0.647595  0.127317\n",
      "          snli                common     0.474808  0.236499\n",
      "                              msp        0.338393  0.209378\n",
      "                              pps        0.626404  0.220724\n",
      "          sst2                common     0.000000  0.000000\n",
      "                              msp        0.000000  0.000000\n",
      "                              pps        0.000000  0.000000\n",
      "sst2      counterfactual-imdb common     0.000000  0.000000\n",
      "                              msp        0.000000  0.000000\n",
      "                              pps        0.000000  0.000000\n",
      "          imdb                common     0.000000  0.000000\n",
      "                              msp        0.000000  0.000000\n",
      "                              pps        0.000000  0.000000\n",
      "          rte                 common     0.400000       NaN\n",
      "                              msp        0.436862  0.263246\n",
      "                              pps        0.610255  0.170939\n",
      "          snli                common     0.581531  0.213770\n",
      "                              msp        0.312519  0.218547\n",
      "                              pps        0.579271  0.236085\n"
     ]
    }
   ],
   "source": [
    "overlaps_summary = grouped_overlaps.mean()\n",
    "overlaps_summary['std'] = grouped_overlaps.std()['overlap']\n",
    "overlaps_summary = overlaps_summary.rename(columns = {'overlap':'mean'})\n",
    "print(overlaps_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps_summary.to_csv(os.path.join('.', 'error_analysis', 'ood_error_overlaps_stats.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst2 in domain msp 698\n",
      "sst2 out domain msp 698\n",
      "sst2 in domain pps 698\n",
      "sst2 out domain pps 698\n",
      "=============================================\n",
      "imdb in domain msp 20000\n",
      "imdb out domain msp 20000\n",
      "imdb in domain pps 20000\n",
      "imdb out domain pps 20000\n"
     ]
    }
   ],
   "source": [
    "print('sst2 in domain', 'msp', len(signals[('sst2', 'sst2')]['msp']))\n",
    "print('sst2 out domain', 'msp',len(signals[('imdb', 'sst2')]['msp']))\n",
    "print('sst2 in domain', 'pps',len(signals[('sst2', 'sst2')]['pps']))\n",
    "print('sst2 out domain', 'pps',len(signals[('imdb', 'sst2')]['pps']))\n",
    "print('='*45)\n",
    "print('imdb in domain', 'msp', len(signals[('imdb', 'imdb')]['msp']))\n",
    "print('imdb out domain', 'msp',len(signals[('sst2', 'imdb')]['msp']))\n",
    "print('imdb in domain', 'pps',len(signals[('imdb', 'imdb')]['pps']))\n",
    "print('imdb out domain', 'pps',len(signals[('sst2', 'imdb')]['pps']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snli sst2 in domain msp 10000\n",
      "snli imdb in domain msp 10000\n",
      "=============================================\n",
      "rte sst2 in domain msp 277\n",
      "rte imdb in domain msp 277\n"
     ]
    }
   ],
   "source": [
    "print('snli', 'sst2 in domain', 'msp', len(signals[('sst2', 'snli')]['msp']))\n",
    "print('snli', 'imdb in domain', 'msp',len(signals[('imdb', 'snli')]['msp']))\n",
    "print('='*45)\n",
    "print('rte', 'sst2 in domain', 'msp', len(signals[('sst2', 'rte')]['msp']))\n",
    "print('rte', 'imdb in domain', 'msp',len(signals[('imdb', 'rte')]['msp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snli sst2 in domain pps 10000\n",
      "snli imdb in domain pps 10000\n",
      "=============================================\n",
      "rte sst2 in domain pps 277\n",
      "rte imdb in domain pps 277\n"
     ]
    }
   ],
   "source": [
    "print('snli', 'sst2 in domain', 'pps', len(signals[('sst2', 'snli')]['pps']))\n",
    "print('snli', 'imdb in domain', 'pps',len(signals[('imdb', 'snli')]['pps']))\n",
    "print('='*45)\n",
    "print('rte', 'sst2 in domain', 'pps', len(signals[('sst2', 'rte')]['pps']))\n",
    "print('rte', 'imdb in domain', 'pps',len(signals[('imdb', 'rte')]['pps']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
