{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_px(ppl, lls):\n",
    "    lengths = np.array([len(ll) for ll in lls])\n",
    "    logpx = np.log(ppl) * lengths * -1\n",
    "    return logpx\n",
    "\n",
    "def compute_auroc_all(id_msp, id_px, id_ppl, ood_msp, ood_px, ood_ppl, do_print=False):\n",
    "    score_px = compute_auroc(-id_px, -ood_px)\n",
    "    score_py = compute_auroc(-id_msp, -ood_msp)\n",
    "    score_ppl = compute_auroc(id_ppl, ood_ppl)\n",
    "    if do_print:\n",
    "        print(f\"P(x): {score_px:.3f}\")\n",
    "        print(f\"P(y | x): {score_py:.3f}\")\n",
    "        print(f\"Perplexity: {score_ppl:.3f}\")\n",
    "    scores = {\n",
    "        'p_x': score_px,\n",
    "        'p_y': score_py,\n",
    "        'ppl': score_ppl\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_auroc(id_pps, ood_pps, normalize=False, return_curve=False):\n",
    "    y = np.concatenate((np.ones_like(ood_pps), np.zeros_like(id_pps)))\n",
    "    scores = np.concatenate((ood_pps, id_pps))\n",
    "    if normalize:\n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    if return_curve:\n",
    "        return roc_curve(y, scores)\n",
    "    else:\n",
    "        return 100*roc_auc_score(y, scores)\n",
    "\n",
    "def compute_far(id_pps, ood_pps, rate=5, return_indices=False):\n",
    "    if return_indices:\n",
    "        cut_off = np.percentile(ood_pps, rate)\n",
    "        id_indices = [i for i, pps in enumerate(id_pps) if pps > cut_off]\n",
    "        ood_indices = [i for i, pps in enumerate(ood_pps) if pps > cut_off]\n",
    "        return {'id': id_indices, 'ood': ood_indices}\n",
    "    else:\n",
    "        incorrect = len(id_pps[id_pps > np.percentile(ood_pps, rate)])\n",
    "        return 100*incorrect / len(id_pps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_metric_all(id_msp, id_px, id_ppl, ood_msp, ood_px, ood_ppl, metric='auroc', do_print=False):\n",
    "    if metric == 'auroc':\n",
    "        score_px = compute_auroc(-id_px, -ood_px)\n",
    "        score_py = compute_auroc(-id_msp, -ood_msp)\n",
    "        score_ppl = compute_auroc(id_ppl, ood_ppl)\n",
    "    elif metric == 'far':\n",
    "        score_px = compute_far(-id_px, -ood_px)\n",
    "        score_py = compute_far(-id_msp, -ood_msp)\n",
    "        score_ppl = compute_far(id_ppl, ood_ppl)\n",
    "    else:\n",
    "        raise Exception('Invalid metric name')\n",
    "\n",
    "    if do_print:\n",
    "        print(f\"Metric {metric}:\")\n",
    "        print(f\"P(x): {score_px:.3f}\")\n",
    "        print(f\"P(y | x): {score_py:.3f}\")\n",
    "        print(f\"Perplexity: {score_ppl:.3f}\\n\")\n",
    "\n",
    "    scores = {\n",
    "        'p_x': score_px,\n",
    "        'p_y': score_py,\n",
    "        'ppl': score_ppl\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_model_out(fname):\n",
    "    ftype = fname.split('.')[1]\n",
    "    \n",
    "    if ftype == 'pkl':\n",
    "        with open(fname, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    elif ftype == 'npy':\n",
    "        return np.load(fname)\n",
    "    else:\n",
    "        raise KeyError(f'{ftype} not supported')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Documents\\NYU\\2020_Fall\\nlp\\project\\ood-detection\n"
     ]
    }
   ],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(repo, 'output')\n",
    "fig_dir = os.path.join(repo, 'figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = ['imdb', 'sst2']\n",
    "eval_sets = ['imdb', 'sst2', 'snli', 'counterfactual-imdb', 'rte']\n",
    "methods = ['msp', 'lls', 'pps']\n",
    "\n",
    "signals = {}\n",
    "for train_set in train_sets:\n",
    "    for eval_set in eval_sets:\n",
    "        signals[(train_set, eval_set)] = {method: None for method in methods}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "method2ftype={\n",
    "    'msp': 'npy',\n",
    "    'lls': 'pkl',\n",
    "    'pps': 'npy',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        return [int(x) for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_dir = os.path.join(repo, 'roberta')\n",
    "\n",
    "subsample_indices = {\n",
    "    data_name: get_indices(os.path.join(roberta_dir, f'{data_name}_indices.txt'))\n",
    "    for data_name in train_sets\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = {\n",
    "    'imdb': '5e-5',\n",
    "    'sst2': '5e-5',\n",
    "}\n",
    "\n",
    "methods = ['lls', 'pps']\n",
    "not_readys = []\n",
    "\n",
    "for (train_set, eval_set), signals_dict in signals.items():\n",
    "    for method in methods:\n",
    "        signal_fname = os.path.join(output_dir, 'gpt2', train_set, f'{eval_set}_{best_lr[train_set]}_{method}.{method2ftype[method]}')\n",
    "        if not os.path.exists(signal_fname):\n",
    "            not_readys.append((train_set, eval_set, method))\n",
    "            continue\n",
    "        \n",
    "        signal = read_model_out(signal_fname)\n",
    "        if train_set == eval_set:\n",
    "            idxs = subsample_indices[train_set]\n",
    "            signal = [signal[idx] for idx in idxs]\n",
    "        \n",
    "        signals_dict[method] = signal\n",
    "        \n",
    "for not_ready in not_readys:\n",
    "    print(not_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['msp']\n",
    "not_readys = []\n",
    "\n",
    "model_type = 'roberta-large'\n",
    "\n",
    "for (train_set, eval_set), signals_dict in signals.items():\n",
    "    for method in methods:\n",
    "        signal_fname = os.path.join(output_dir, 'roberta', train_set, f'{model_type}_{eval_set}_{method}.{method2ftype[method]}')\n",
    "        if not os.path.exists(signal_fname):\n",
    "            not_readys.append((train_set, eval_set, method))\n",
    "            continue\n",
    "\n",
    "        signals_dict[method] = read_model_out(signal_fname)\n",
    "        \n",
    "for not_ready in not_readys:\n",
    "    print(not_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Error Indices by FAR95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score2plot = {\n",
    "    'p_x': r'GPT2: $p(x)$',\n",
    "    'ppl': 'GPT2: PPL',\n",
    "    'p_y': 'RoBERTa: MSP',\n",
    "}\n",
    "\n",
    "metric2plot = {\n",
    "    'auroc': 'AUROC',\n",
    "    'far': 'FAR95'\n",
    "}\n",
    "\n",
    "dataset2plot = {\n",
    "    'imdb': 'IMDB',\n",
    "    'sst2': 'SST-2',\n",
    "    'snli': 'SNLI',\n",
    "    'counterfactual-imdb': 'c-IMDB',\n",
    "    'rte': 'RTE',\n",
    "}\n",
    "\n",
    "error_indices = {}\n",
    "not_ready = []\n",
    "for train_set in train_sets:\n",
    "    for eval_set in eval_sets:\n",
    "        if train_set == eval_set:\n",
    "            continue\n",
    "        \n",
    "        ood_signal_dict = signals[(train_set, eval_set)]\n",
    "        id_signal_dict = signals[(train_set, train_set)]\n",
    "        \n",
    "        skip=False\n",
    "        for value in ood_signal_dict.values():\n",
    "            if isinstance(value, type(None)):\n",
    "                skip=True\n",
    "                \n",
    "        if skip:\n",
    "            not_ready.append((train_set, eval_set))\n",
    "            continue\n",
    "        \n",
    "        pps_errors = compute_far(id_signal_dict['pps'], ood_signal_dict['pps'], return_indices=True)\n",
    "        msp_errors = compute_far(-id_signal_dict['msp'], -ood_signal_dict['msp'], return_indices=True)\n",
    "        \n",
    "        error_indices[(train_set, eval_set)] = {'pps': pps_errors, 'msp': msp_errors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('imdb', 'sst2'), ('imdb', 'snli'), ('imdb', 'counterfactual-imdb'), ('imdb', 'rte'), ('sst2', 'imdb'), ('sst2', 'snli'), ('sst2', 'counterfactual-imdb'), ('sst2', 'rte')]\n"
     ]
    }
   ],
   "source": [
    "print(list(error_indices.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_parts = {}\n",
    "for ood_key, errors_dict in error_indices.items():\n",
    "    pps_id = set(errors_dict['pps']['id'])\n",
    "    pps_ood = set(errors_dict['pps']['ood'])\n",
    "    msp_id = set(errors_dict['msp']['id'])\n",
    "    msp_ood = set(errors_dict['msp']['ood'])\n",
    "    \n",
    "    union = {\n",
    "        'id': pps_id.union(msp_id),\n",
    "        'ood': pps_ood.union(msp_ood),\n",
    "    }\n",
    "    \n",
    "    common = {\n",
    "        'id': pps_id.intersection(msp_id),\n",
    "        'ood': pps_ood.intersection(msp_ood),\n",
    "    }\n",
    "    \n",
    "    pps_only = {\n",
    "        'id': pps_id.difference(msp_id),\n",
    "        'ood': pps_ood.difference(msp_ood),\n",
    "    }\n",
    "    \n",
    "    msp_only = {\n",
    "        'id': msp_id.difference(pps_id),\n",
    "        'ood': msp_ood.difference(pps_ood),\n",
    "    }\n",
    "    \n",
    "    indices_parts[ood_key] = {\n",
    "        'union': union,\n",
    "        'common': common,\n",
    "        'pps': pps_only,\n",
    "        'msp': msp_only,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  in domain                  ood  total count  common count  msp only count  \\\n",
      "0      imdb                 sst2        19413          9482            7527   \n",
      "1      imdb                 snli        28368         11665             634   \n",
      "2      imdb  counterfactual-imdb        21877         17398            1169   \n",
      "3      imdb                  rte        20014          4278              43   \n",
      "4      sst2                 imdb        25437         22813            1428   \n",
      "5      sst2                 snli        10492          9157             575   \n",
      "6      sst2  counterfactual-imdb         2951          2344             421   \n",
      "7      sst2                  rte          813           414             108   \n",
      "\n",
      "   pps only count  common ratio  msp only ratio  pps only ratio  \n",
      "0            2404      0.488436        0.387730        0.123835  \n",
      "1           16069      0.411203        0.022349        0.566448  \n",
      "2            3310      0.795264        0.053435        0.151300  \n",
      "3           15693      0.213750        0.002148        0.784101  \n",
      "4            1196      0.896843        0.056139        0.047018  \n",
      "5             760      0.872760        0.054804        0.072436  \n",
      "6             186      0.794307        0.142664        0.063029  \n",
      "7             291      0.509225        0.132841        0.357934  \n"
     ]
    }
   ],
   "source": [
    "stats = []\n",
    "for (indomain, ood), partitions in indices_parts.items():\n",
    "    total_count = len(partitions['union']['id']) + len(partitions['union']['ood'])\n",
    "    common_count = len(partitions['common']['id']) + len(partitions['common']['ood'])\n",
    "    msp_count = len(partitions['msp']['id']) + len(partitions['msp']['ood']) + common_count\n",
    "    pps_count = len(partitions['pps']['id']) + len(partitions['pps']['ood']) + common_count\n",
    "    \n",
    "    row = {\n",
    "        'in domain': indomain,\n",
    "        'ood': ood,\n",
    "        'total count': total_count,\n",
    "        'common count': common_count,\n",
    "        'msp only count': msp_count - common_count,\n",
    "        'pps only count': pps_count - common_count,\n",
    "        'common ratio': common_count/total_count,\n",
    "        'msp only ratio': (msp_count - common_count)/total_count,\n",
    "        'pps only ratio': (pps_count - common_count)/total_count,\n",
    "    }\n",
    "    \n",
    "    stats.append(row)\n",
    "print(pd.DataFrame(stats))\n",
    "pd.DataFrame(stats).to_csv(os.path.join('.', 'error_analysis', 'error_counts_ratios.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('.', 'all_val_data.p'), 'rb') as f:\n",
    "    datasets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb snli common ood\n",
      "imdb snli msp ood\n",
      "imdb snli pps ood\n",
      "imdb rte common ood\n",
      "imdb rte msp ood\n",
      "imdb rte pps ood\n",
      "sst2 snli common ood\n",
      "sst2 snli msp ood\n",
      "sst2 snli pps ood\n",
      "sst2 rte common ood\n",
      "sst2 rte msp ood\n",
      "sst2 rte pps ood\n"
     ]
    }
   ],
   "source": [
    "nsample = 10\n",
    "examples = []\n",
    "ignore_ood = ['sst2', 'imdb', 'counterfactual-imdb']\n",
    "parts = ['common', 'msp', 'pps']\n",
    "domains = ['ood']\n",
    "\n",
    "for (indomain, ood), partitions in indices_parts.items():\n",
    "    if ood in ignore_ood:\n",
    "        continue\n",
    "        \n",
    "    data = {\n",
    "        'id': datasets[('id', 'val', indomain)]['text'],\n",
    "        'ood': datasets[('ood', 'val', ood)]['text'],\n",
    "    }\n",
    "    \n",
    "    for part in parts:\n",
    "        for domain in domains:\n",
    "            sample = np.random.choice(list(partitions[part][domain]), size=nsample, replace=False)\n",
    "            print(indomain, ood, part, domain)\n",
    "            for idx in sample:\n",
    "                examples.append({\n",
    "                    'in domain': indomain,\n",
    "                    'ood': ood,\n",
    "                    'text': data[domain][idx],\n",
    "                    'domain': domain,\n",
    "                    'dataset': indomain if domain == 'id' else ood,\n",
    "                    'partition': part,\n",
    "                })\n",
    "pd.DataFrame(examples).to_csv(os.path.join('.', 'error_analysis', 'error_examples.csv'))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent OOD Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb snli common ood\n",
      "imdb snli msp ood\n",
      "imdb snli pps ood\n",
      "imdb rte common ood\n",
      "imdb rte msp ood\n",
      "imdb rte pps ood\n",
      "sst2 snli common ood\n",
      "sst2 snli msp ood\n",
      "sst2 snli pps ood\n",
      "sst2 rte common ood\n",
      "sst2 rte msp ood\n",
      "sst2 rte pps ood\n"
     ]
    }
   ],
   "source": [
    "ood_stats, ood_examples = [], []\n",
    "\n",
    "tasks = ['snli', 'rte']\n",
    "parts = ['common', 'msp', 'pps']\n",
    "domains = ['ood']\n",
    "\n",
    "nsample = 10\n",
    "\n",
    "for (indomain, ood), partitions in indices_parts.items():\n",
    "    if not ood in tasks:\n",
    "        continue\n",
    "    \n",
    "    total_count = len(partitions['union']['ood'])\n",
    "    common_count = len(partitions['common']['ood'])\n",
    "    msp_count = len(partitions['msp']['ood']) + common_count\n",
    "    pps_count = len(partitions['pps']['ood']) + common_count\n",
    "    \n",
    "    row = {\n",
    "        'in domain': indomain,\n",
    "        'ood': ood,\n",
    "        'total count': total_count,\n",
    "        'common count': common_count,\n",
    "        'msp only count': msp_count - common_count,\n",
    "        'pps only count': pps_count - common_count,\n",
    "        'common ratio': common_count/total_count,\n",
    "        'msp only ratio': (msp_count - common_count)/total_count,\n",
    "        'pps only ratio': (pps_count - common_count)/total_count,\n",
    "    }\n",
    "    \n",
    "    ood_stats.append(row)\n",
    "    \n",
    "    \n",
    "    data = {'ood': datasets[('ood', 'val', ood)]['text']}\n",
    "    for part in parts:\n",
    "        for domain in domains:\n",
    "            sample = np.random.choice(list(partitions[part][domain]), size=nsample, replace=False)\n",
    "            print(indomain, ood, part, domain)\n",
    "            for idx in sample:\n",
    "                ood_examples.append({\n",
    "                    'in domain': indomain,\n",
    "                    'ood': ood,\n",
    "                    'text': data[domain][idx],\n",
    "                    'domain': domain,\n",
    "                    'dataset': indomain if domain == 'id' else ood,\n",
    "                    'partition': part,\n",
    "                })\n",
    "    \n",
    "    \n",
    "pd.DataFrame(ood_stats).to_csv(os.path.join('.', 'error_analysis', 'ood_error_counts_ratios.csv'))\n",
    "pd.DataFrame(ood_examples).to_csv(os.path.join('.', 'error_analysis', 'ood_error_examples.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst2 in domain msp 698\n",
      "sst2 out domain msp 872\n",
      "sst2 in domain pps 698\n",
      "sst2 out domain pps 1821\n",
      "=============================================\n",
      "imdb in domain msp 20000\n",
      "imdb out domain msp 25000\n",
      "imdb in domain pps 20000\n",
      "imdb out domain pps 25000\n"
     ]
    }
   ],
   "source": [
    "print('sst2 in domain', 'msp', len(signals[('sst2', 'sst2')]['msp']))\n",
    "print('sst2 out domain', 'msp',len(signals[('imdb', 'sst2')]['msp']))\n",
    "print('sst2 in domain', 'pps',len(signals[('sst2', 'sst2')]['pps']))\n",
    "print('sst2 out domain', 'pps',len(signals[('imdb', 'sst2')]['pps']))\n",
    "print('='*45)\n",
    "print('imdb in domain', 'msp', len(signals[('imdb', 'imdb')]['msp']))\n",
    "print('imdb out domain', 'msp',len(signals[('sst2', 'imdb')]['msp']))\n",
    "print('imdb in domain', 'pps',len(signals[('imdb', 'imdb')]['pps']))\n",
    "print('imdb out domain', 'pps',len(signals[('sst2', 'imdb')]['pps']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snli sst2 in domain msp 10000\n",
      "snli imdb in domain msp 10000\n",
      "=============================================\n",
      "rte sst2 in domain msp 277\n",
      "rte imdb in domain msp 277\n"
     ]
    }
   ],
   "source": [
    "print('snli', 'sst2 in domain', 'msp', len(signals[('sst2', 'snli')]['msp']))\n",
    "print('snli', 'imdb in domain', 'msp',len(signals[('imdb', 'snli')]['msp']))\n",
    "print('='*45)\n",
    "print('rte', 'sst2 in domain', 'msp', len(signals[('sst2', 'rte')]['msp']))\n",
    "print('rte', 'imdb in domain', 'msp',len(signals[('imdb', 'rte')]['msp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snli sst2 in domain pps 10000\n",
      "snli imdb in domain pps 10000\n",
      "=============================================\n",
      "rte sst2 in domain pps 277\n",
      "rte imdb in domain pps 277\n"
     ]
    }
   ],
   "source": [
    "print('snli', 'sst2 in domain', 'pps', len(signals[('sst2', 'snli')]['pps']))\n",
    "print('snli', 'imdb in domain', 'pps',len(signals[('imdb', 'snli')]['pps']))\n",
    "print('='*45)\n",
    "print('rte', 'sst2 in domain', 'pps', len(signals[('sst2', 'rte')]['pps']))\n",
    "print('rte', 'imdb in domain', 'pps',len(signals[('imdb', 'rte')]['pps']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
