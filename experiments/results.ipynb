{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_px(ppl, lls):\n",
    "    lengths = np.array([len(ll) for ll in lls])\n",
    "    logpx = np.log(ppl) * lengths * -1\n",
    "    return logpx\n",
    "\n",
    "def compute_auroc_all(id_msp, id_px, id_ppl, ood_msp, ood_px, ood_ppl, do_print=False):\n",
    "    score_px = compute_auroc(-id_px, -ood_px)\n",
    "    score_py = compute_auroc(-id_msp, -ood_msp)\n",
    "    score_ppl = compute_auroc(id_ppl, ood_ppl)\n",
    "    if do_print:\n",
    "        print(f\"P(x): {score_px:.3f}\")\n",
    "        print(f\"P(y | x): {score_py:.3f}\")\n",
    "        print(f\"Perplexity: {score_ppl:.3f}\")\n",
    "    scores = {\n",
    "        'p_x': score_px,\n",
    "        'p_y': score_py,\n",
    "        'ppl': score_ppl\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_auroc(id_pps, ood_pps, normalize=False, return_curve=False):\n",
    "    y = np.concatenate((np.ones_like(ood_pps), np.zeros_like(id_pps)))\n",
    "    scores = np.concatenate((ood_pps, id_pps))\n",
    "    if normalize:\n",
    "        scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "    if return_curve:\n",
    "        return roc_curve(y, scores)\n",
    "    else:\n",
    "        return 100*roc_auc_score(y, scores)\n",
    "\n",
    "def compute_far(id_pps, ood_pps, rate=5):\n",
    "    incorrect = len(id_pps[id_pps > np.percentile(ood_pps, rate)])\n",
    "    return 100*incorrect / len(id_pps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compute_metric_all(id_msp, id_px, id_ppl, ood_msp, ood_px, ood_ppl, metric='auroc', do_print=False):\n",
    "    if metric == 'auroc':\n",
    "        score_px = compute_auroc(-id_px, -ood_px)\n",
    "        score_py = compute_auroc(-id_msp, -ood_msp)\n",
    "        score_ppl = compute_auroc(id_ppl, ood_ppl)\n",
    "    elif metric == 'far':\n",
    "        score_px = compute_far(-id_px, -ood_px)\n",
    "        score_py = compute_far(-id_msp, -ood_msp)\n",
    "        score_ppl = compute_far(id_ppl, ood_ppl)\n",
    "    else:\n",
    "        raise Exception('Invalid metric name')\n",
    "\n",
    "    if do_print:\n",
    "        print(f\"Metric {metric}:\")\n",
    "        print(f\"P(x): {score_px:.3f}\")\n",
    "        print(f\"P(y | x): {score_py:.3f}\")\n",
    "        print(f\"Perplexity: {score_ppl:.3f}\\n\")\n",
    "\n",
    "    scores = {\n",
    "        'p_x': score_px,\n",
    "        'p_y': score_py,\n",
    "        'ppl': score_ppl\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_model_out(fname):\n",
    "    ftype = fname.split('.')[1]\n",
    "    \n",
    "    if ftype == 'pkl':\n",
    "        with open(fname, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    elif ftype == 'npy':\n",
    "        return np.load(fname)\n",
    "    else:\n",
    "        raise KeyError(f'{ftype} not supported')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presettings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Documents\\NYU\\2020_Fall\\nlp\\project\\ood-detection\n"
     ]
    }
   ],
   "source": [
    "repo = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(repo, 'output')\n",
    "fig_dir = os.path.join(repo, 'figs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = ['imdb', 'sst2']\n",
    "eval_sets = ['imdb', 'sst2', 'snli', 'counterfactual-imdb', 'rte']\n",
    "methods = ['msp', 'lls', 'pps']\n",
    "\n",
    "signals = {}\n",
    "for train_set in train_sets:\n",
    "    for eval_set in eval_sets:\n",
    "        signals[(train_set, eval_set)] = {method: None for method in methods}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "method2ftype={\n",
    "    'msp': 'npy',\n",
    "    'lls': 'pkl',\n",
    "    'pps': 'npy',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        return [int(x) for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_dir = os.path.join(repo, 'roberta')\n",
    "\n",
    "subsample_indices = {\n",
    "    data_name: get_indices(os.path.join(roberta_dir, f'{data_name}_indices.txt'))\n",
    "    for data_name in train_sets\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = {\n",
    "    'imdb': '5e-5',\n",
    "    'sst2': '5e-5',\n",
    "}\n",
    "\n",
    "methods = ['lls', 'pps']\n",
    "not_readys = []\n",
    "\n",
    "for (train_set, eval_set), signals_dict in signals.items():\n",
    "    for method in methods:\n",
    "        signal_fname = os.path.join(output_dir, 'gpt2', train_set, f'{eval_set}_{best_lr[train_set]}_{method}.{method2ftype[method]}')\n",
    "        if not os.path.exists(signal_fname):\n",
    "            not_readys.append((train_set, eval_set, method))\n",
    "            continue\n",
    "        \n",
    "        signal = read_model_out(signal_fname)\n",
    "        if train_set == eval_set:\n",
    "            idxs = subsample_indices[train_set]\n",
    "            signal = [signal[idx] for idx in idxs]\n",
    "            if method == 'pps':\n",
    "                signal = np.array(signal)\n",
    "        \n",
    "        signals_dict[method] = signal\n",
    "        \n",
    "for not_ready in not_readys:\n",
    "    print(not_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['msp']\n",
    "not_readys = []\n",
    "\n",
    "model_type = 'roberta-large'\n",
    "\n",
    "for (train_set, eval_set), signals_dict in signals.items():\n",
    "    for method in methods:\n",
    "        signal_fname = os.path.join(output_dir, 'roberta', train_set, f'{model_type}_{eval_set}_{method}.{method2ftype[method]}')\n",
    "        if not os.path.exists(signal_fname):\n",
    "            not_readys.append((train_set, eval_set, method))\n",
    "            continue\n",
    "\n",
    "        signals_dict[method] = read_model_out(signal_fname)\n",
    "        \n",
    "for not_ready in not_readys:\n",
    "    print(not_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Method      score in_domain out_domain metric\n",
      "0   GPT2: $p(x)$   0.394509      IMDB      SST-2  AUROC\n",
      "1   RoBERTa: MSP  70.281889      IMDB      SST-2  AUROC\n",
      "2      GPT2: PPL  91.284841      IMDB      SST-2  AUROC\n",
      "3   GPT2: $p(x)$  99.990000      IMDB      SST-2  FAR95\n",
      "4   RoBERTa: MSP  80.905000      IMDB      SST-2  FAR95\n",
      "5      GPT2: PPL  50.785000      IMDB      SST-2  FAR95\n",
      "6   GPT2: $p(x)$   0.166909      IMDB       SNLI  AUROC\n",
      "7   RoBERTa: MSP  94.410856      IMDB       SNLI  AUROC\n",
      "8      GPT2: PPL  71.344013      IMDB       SNLI  AUROC\n",
      "9   GPT2: $p(x)$  99.980000      IMDB       SNLI  FAR95\n",
      "10  RoBERTa: MSP  14.000000      IMDB       SNLI  FAR95\n",
      "11     GPT2: PPL  91.170000      IMDB       SNLI  FAR95\n",
      "12  GPT2: $p(x)$  41.484174      IMDB     c-IMDB  AUROC\n",
      "13  RoBERTa: MSP  63.987969      IMDB     c-IMDB  AUROC\n",
      "14     GPT2: PPL  55.156607      IMDB     c-IMDB  AUROC\n",
      "15  GPT2: $p(x)$  94.670000      IMDB     c-IMDB  FAR95\n",
      "16  RoBERTa: MSP  81.240000      IMDB     c-IMDB  FAR95\n",
      "17     GPT2: PPL  91.950000      IMDB     c-IMDB  FAR95\n",
      "18  GPT2: $p(x)$   4.719386      IMDB        RTE  AUROC\n",
      "19  RoBERTa: MSP  92.000903      IMDB        RTE  AUROC\n",
      "20     GPT2: PPL  51.277148      IMDB        RTE  AUROC\n",
      "21  GPT2: $p(x)$  99.935000      IMDB        RTE  FAR95\n",
      "22  RoBERTa: MSP  20.290000      IMDB        RTE  FAR95\n",
      "23     GPT2: PPL  98.540000      IMDB        RTE  FAR95\n",
      "24  GPT2: $p(x)$  99.947754     SST-2       IMDB  AUROC\n",
      "25  RoBERTa: MSP  64.283467     SST-2       IMDB  AUROC\n",
      "26     GPT2: PPL  89.982304     SST-2       IMDB  AUROC\n",
      "27  GPT2: $p(x)$   0.000000     SST-2       IMDB  FAR95\n",
      "28  RoBERTa: MSP  70.343840     SST-2       IMDB  FAR95\n",
      "29     GPT2: PPL  37.106017     SST-2       IMDB  FAR95\n",
      "30  GPT2: $p(x)$  69.849728     SST-2       SNLI  AUROC\n",
      "31  RoBERTa: MSP  90.660895     SST-2       SNLI  AUROC\n",
      "32     GPT2: PPL  80.643682     SST-2       SNLI  AUROC\n",
      "33  GPT2: $p(x)$  62.034384     SST-2       SNLI  FAR95\n",
      "34  RoBERTa: MSP  33.237822     SST-2       SNLI  FAR95\n",
      "35     GPT2: PPL  59.742120     SST-2       SNLI  FAR95\n",
      "36  GPT2: $p(x)$  99.970466     SST-2     c-IMDB  AUROC\n",
      "37  RoBERTa: MSP  67.715927     SST-2     c-IMDB  AUROC\n",
      "38     GPT2: PPL  91.913312     SST-2     c-IMDB  AUROC\n",
      "39  GPT2: $p(x)$   0.000000     SST-2     c-IMDB  FAR95\n",
      "40  RoBERTa: MSP  64.040115     SST-2     c-IMDB  FAR95\n",
      "41     GPT2: PPL  30.372493     SST-2     c-IMDB  FAR95\n",
      "42  GPT2: $p(x)$  96.071809     SST-2        RTE  AUROC\n",
      "43  RoBERTa: MSP  90.210814     SST-2        RTE  AUROC\n",
      "44     GPT2: PPL  81.792745     SST-2        RTE  AUROC\n",
      "45  GPT2: $p(x)$  19.914040     SST-2        RTE  FAR95\n",
      "46  RoBERTa: MSP  37.106017     SST-2        RTE  FAR95\n",
      "47     GPT2: PPL  63.323782     SST-2        RTE  FAR95\n"
     ]
    }
   ],
   "source": [
    "metrics = ['auroc', 'far']\n",
    "\n",
    "metric_summary = []\n",
    "\n",
    "score2plot = {\n",
    "    'p_x': r'GPT2: $p(x)$',\n",
    "    'ppl': 'GPT2: PPL',\n",
    "    'p_y': 'RoBERTa: MSP',\n",
    "}\n",
    "\n",
    "metric2plot = {\n",
    "    'auroc': 'AUROC',\n",
    "    'far': 'FAR95'\n",
    "}\n",
    "\n",
    "dataset2plot = {\n",
    "    'imdb': 'IMDB',\n",
    "    'sst2': 'SST-2',\n",
    "    'snli': 'SNLI',\n",
    "    'counterfactual-imdb': 'c-IMDB',\n",
    "    'rte': 'RTE',\n",
    "}\n",
    "\n",
    "not_ready = []\n",
    "for train_set in train_sets:\n",
    "    for eval_set in eval_sets:\n",
    "        if train_set == eval_set:\n",
    "            continue\n",
    "        \n",
    "        ood_signal_dict = signals[(train_set, eval_set)]\n",
    "        id_signal_dict = signals[(train_set, train_set)]\n",
    "        \n",
    "        skip=False\n",
    "        for value in ood_signal_dict.values():\n",
    "            if isinstance(value, type(None)):\n",
    "                skip=True\n",
    "                \n",
    "        if skip:\n",
    "            not_ready.append((train_set, eval_set))\n",
    "            continue\n",
    "            \n",
    "        ood_px = compute_px(ood_signal_dict['pps'], ood_signal_dict['lls'])\n",
    "        id_px = compute_px(id_signal_dict['pps'], id_signal_dict['lls'])\n",
    "               \n",
    "        for metric in metrics:\n",
    "            scores = compute_metric_all(\n",
    "                id_msp=id_signal_dict['msp'],\n",
    "                id_px=id_px,\n",
    "                id_ppl=id_signal_dict['pps'],\n",
    "                ood_msp=ood_signal_dict['msp'],\n",
    "                ood_px=ood_px,\n",
    "                ood_ppl=ood_signal_dict['pps'],\n",
    "                metric=metric,\n",
    "                do_print=verbose\n",
    "            )\n",
    "            \n",
    "            for score_key, score_value in scores.items():\n",
    "                row = {'Method': score2plot[score_key], 'score': score_value}\n",
    "            \n",
    "                row['in_domain'] = dataset2plot[train_set]\n",
    "                row['out_domain'] = dataset2plot[eval_set]\n",
    "                row['metric'] = metric2plot[metric]\n",
    "\n",
    "                metric_summary.append(row)        \n",
    "        \n",
    "print(pd.DataFrame(metric_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_size=24\n",
    "label_size=18\n",
    "annot_size=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_plot(\n",
    "    df=None,\n",
    "    x='out_domain',\n",
    "    y='score',\n",
    "    hue='Method',\n",
    "    title=None,\n",
    "    xlabel='',\n",
    "    ylabel='',\n",
    "    palette='colorblind',\n",
    "    ylim=[0,110],\n",
    "    yticks=np.arange(0,110,20),\n",
    "    order=None,\n",
    "    val_offset = 5,\n",
    "    hue_order=None,\n",
    "    figsize=(10,5),\n",
    "    legend_pos='upper left',\n",
    "    legend_anchor=(1,1),\n",
    "    legend_on=True,\n",
    "    ax = None,\n",
    "):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "    splot = sns.barplot(\n",
    "        data=df, \n",
    "        x=x, \n",
    "        y=y,\n",
    "        hue=hue,\n",
    "        palette=palette,\n",
    "        hue_order=hue_order,\n",
    "        order=order,\n",
    "        ax=ax,\n",
    "    )\n",
    "    \n",
    "    for p in splot.patches:\n",
    "        splot.annotate(\n",
    "            f'{p.get_height():.1f}',\n",
    "            (p.get_x() + p.get_width() / 2, p.get_height() + val_offset),\n",
    "            ha='center', va='center',\n",
    "            fontsize=annot_size\n",
    "        )\n",
    "    \n",
    "    if not title is None:\n",
    "        ax.set_title(title, fontsize=title_size)\n",
    "        \n",
    "    ax.set_xlabel(xlabel, fontsize=label_size)\n",
    "    ax.set_ylabel(ylabel, fontsize=label_size)\n",
    "    \n",
    "    ax.legend(loc=legend_pos, bbox_to_anchor=legend_anchor).set_visible(legend_on)\n",
    "    ax.set_ylim(ylim)\n",
    "    \n",
    "    splot.set_yticklabels(yticks, size=annot_size)\n",
    "    splot.set_xticklabels(order, size=annot_size)\n",
    "    \n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    fig.tight_layout()  \n",
    "    \n",
    "    if ax is None:\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5622ec0a847140d6b44473921f4b3cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55adf2b7cbd34ab99762c56324f7ce52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f65a9721ec04dc2ad20ef51699ec120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1f8b0e62ff4a298eb6817f1593af10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_df = pd.DataFrame(metric_summary)\n",
    "xlabel = 'Out-of-Domain Sets'\n",
    "\n",
    "order_all = ['c-IMDB', 'IMDB', 'SST-2', 'SNLI', 'RTE']\n",
    "hue_order = ['RoBERTa: MSP',  'GPT2: PPL', r'GPT2: $p(x)$']\n",
    "palette = {\n",
    "    'RoBERTa: MSP':'tab:orange',\n",
    "    'GPT2: PPL':'tab:cyan',\n",
    "    r'GPT2: $p(x)$':'tab:blue',\n",
    "}\n",
    "figsize = (10, 5)\n",
    "\n",
    "ylim = [0, 115]\n",
    "legend_pos = 'upper left'\n",
    "legend_anchor=(0,1.2)\n",
    "\n",
    "save = False\n",
    "fig_ftype = 'jpg'\n",
    "\n",
    "for metric in summary_df['metric'].unique():\n",
    "    sub_df = summary_df.loc[summary_df['metric'] == metric, :]\n",
    "    \n",
    "    for in_domain in sub_df['in_domain'].unique():\n",
    "        subsub_df = sub_df.loc[sub_df['in_domain'] == in_domain, :]\n",
    "        \n",
    "        order=[out_domain for out_domain in order_all if out_domain in subsub_df['out_domain'].unique()]\n",
    "        \n",
    "        fig = my_plot(\n",
    "            df=subsub_df,\n",
    "#             title=f'{in_domain}',\n",
    "            xlabel=xlabel,\n",
    "#             ylabel=metric,\n",
    "            order=order,\n",
    "            hue_order=hue_order,\n",
    "            palette=palette,\n",
    "            figsize=figsize,\n",
    "            ylim=ylim,\n",
    "            legend_pos=legend_pos,\n",
    "            legend_anchor=legend_anchor,\n",
    "        )\n",
    "        \n",
    "        if save:\n",
    "            os.makedirs(fig_dir, exist_ok=True)\n",
    "            fig.savefig(os.path.join(fig_dir, f'{in_domain}_{metric}.{fig_ftype}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(metric_summary)\n",
    "xlabel = 'Out-of-Domain Sets'\n",
    "\n",
    "order_all = ['c-IMDB', 'IMDB', 'SST-2', 'SNLI', 'RTE']\n",
    "hue_order = ['RoBERTa: MSP',  'GPT2: PPL', r'GPT2: $p(x)$']\n",
    "palette = {\n",
    "    'RoBERTa: MSP':'tab:orange',\n",
    "    'GPT2: PPL':'tab:cyan',\n",
    "    r'GPT2: $p(x)$':'tab:blue',\n",
    "}\n",
    "figsize = (20, 10)\n",
    "\n",
    "ylim = [0, 115]\n",
    "legend_pos = 'upper left'\n",
    "legend_anchor=(0,1.2)\n",
    "\n",
    "save = False\n",
    "fig_ftype = 'jpg'\n",
    "\n",
    "fig, ax = plt.subplot(2, 2, figsize=figsize)\n",
    "\n",
    "for m_idx, metric in enumerate(summary_df['metric'].unique()):\n",
    "    sub_df = summary_df.loc[summary_df['metric'] == metric, :]\n",
    "    \n",
    "    for d_idx, in_domain in enumerate(sub_df['in_domain'].unique()):\n",
    "        subsub_df = sub_df.loc[sub_df['in_domain'] == in_domain, :]\n",
    "        \n",
    "        order=[out_domain for out_domain in order_all if out_domain in subsub_df['out_domain'].unique()]\n",
    "        \n",
    "        fig = my_plot(\n",
    "            df=subsub_df,\n",
    "#             title=f'{in_domain}',\n",
    "            xlabel=xlabel,\n",
    "#             ylabel=metric,\n",
    "            order=order,\n",
    "            hue_order=hue_order,\n",
    "            palette=palette,\n",
    "            figsize=figsize,\n",
    "            ylim=ylim,\n",
    "            legend_pos=legend_pos,\n",
    "            legend_anchor=legend_anchor,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fcb06130f548d1ba640d59d2e90eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x153cd564288>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(signals[('imdb', 'imdb')]['pps'])\n",
    "sns.distplot(signals[('imdb', 'counterfactual-imdb')]['pps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.15660655737704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_auroc(signals[('imdb', 'imdb')]['pps'], signals[('imdb', 'counterfactual-imdb')]['pps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9c762e62e34e77b49653c78e4664b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x153cfff4888>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(signals[('imdb', 'imdb')]['msp'])\n",
    "sns.distplot(signals[('imdb', 'counterfactual-imdb')]['msp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25effecda2174af8b659576f27f548d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x153d00738c8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(compute_px(signals[('imdb', 'imdb')]['pps'], signals[('imdb', 'imdb')]['lls']))\n",
    "sns.distplot(compute_px(signals[('imdb', 'sst2')]['pps'], signals[('imdb', 'sst2')]['lls']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6fb8d3ab764ab89315ef7517d0e0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Willi\\Anaconda3\\envs\\DL\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x153d0073a08>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.distplot(compute_px(signals[('sst2', 'sst2')]['pps'], signals[('sst2', 'sst2')]['lls']))\n",
    "sns.distplot(compute_px(signals[('sst2', 'imdb')]['pps'], signals[('sst2', 'imdb')]['lls']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
